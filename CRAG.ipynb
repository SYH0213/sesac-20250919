{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e598d47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 환경변수 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b08f1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# --- Document Loading and Caching ---\n",
    "PDF_PATH = \"data/gemini-2.5-tech_3.pdf\"\n",
    "PARSED_MD_PATH = \"loaddata/llamaparse_output_gemini_3.md\"\n",
    "CHROMA_DB_DIR = \"./chroma_db2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ea157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Splitters\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "\n",
    "# 2. Embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 3. Vectorstore\n",
    "vectorstore = Chroma(persist_directory=CHROMA_DB_DIR, embedding_function=embeddings)\n",
    "\n",
    "# 4. ParentDocumentRetriever\n",
    "store = InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    "    search_kwargs={\"k\":2}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "852c1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_populate_vectorstore():\n",
    "    if vectorstore._collection.count() > 0:\n",
    "        return\n",
    "    if not os.path.exists(PARSED_MD_PATH):\n",
    "        parser = LlamaParse(result_type=\"markdown\", api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"))\n",
    "        documents = parser.load_data(PDF_PATH)\n",
    "        with open(PARSED_MD_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join([doc.text for doc in documents]))\n",
    "    with open(PARSED_MD_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    retriever.add_documents([Document(page_content=text)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "851f6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prompt for History-Aware Retriever\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16b6900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the History-Aware Retriever\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7de30e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prompt for Final Answer Generation\n",
    "ga_system_prompt = (\n",
    "    \"You are a helpful assistant. Your ONLY task is to answer the user's question STRICTLY based on the provided context. \"\n",
    "    \"If the information to answer the question is present in the context, provide a concise answer. \"\n",
    "    \"If the answer cannot be found within the provided context, you MUST say '제공된 문서의 내용으로는 답변할 수 없습니다.' Do NOT use any of your outside knowledge.\"\n",
    "    \"\\n\\nContext:\\n{context}\"\n",
    ")\n",
    "ga_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", ga_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, ga_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d86e55de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create the Document Chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, ga_prompt)\n",
    "\n",
    "# --- RAG Function ---\n",
    "def ask_llm(query, history):\n",
    "    chat_history_for_chain = []\n",
    "    if history:\n",
    "        for message in history:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                chat_history_for_chain.append(HumanMessage(content=message[\"content\"]))\n",
    "            elif message[\"role\"] == \"assistant\":\n",
    "                chat_history_for_chain.append(AIMessage(content=message[\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d505f2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00425235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SBA\\miniconda3\\envs\\mp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\Users\\SBA\\miniconda3\\envs\\mp\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1914: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23071e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68fc09a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is agent memory and how does it function in artificial intelligence?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "question = \"agent memory\"\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e570497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "# --- GraphState 정의 ---\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]\n",
    "    chat_history: list\n",
    "\n",
    "# --- Node 함수들 ---\n",
    "def retrieve(state):\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "    chat_history = state.get(\"chat_history\", [])\n",
    "\n",
    "    # history-aware retriever 사용\n",
    "    retrieved_docs = history_aware_retriever.invoke({\n",
    "        \"input\": question,\n",
    "        \"chat_history\": chat_history\n",
    "    })\n",
    "    return {\"documents\": retrieved_docs, \"question\": question, \"chat_history\": chat_history}\n",
    "\n",
    "def grade_documents(state):\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        if score.binary_score == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            web_search = \"Yes\"\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search, \"chat_history\": state[\"chat_history\"]}\n",
    "\n",
    "def generate(state):\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    chat_history = state[\"chat_history\"]\n",
    "\n",
    "    answer = question_answer_chain.invoke({\n",
    "        \"input\": question,\n",
    "        \"chat_history\": chat_history,\n",
    "        \"context\": documents\n",
    "    })\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": answer, \"chat_history\": chat_history}\n",
    "\n",
    "def transform_query(state):\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": state[\"documents\"], \"question\": better_question, \"chat_history\": state[\"chat_history\"]}\n",
    "\n",
    "def web_search_node(state):\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    documents = state[\"documents\"]\n",
    "    documents.append(Document(page_content=web_results))\n",
    "    return {\"documents\": documents, \"question\": question, \"chat_history\": state[\"chat_history\"]}\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    if state[\"web_search\"] == \"Yes\":\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        return \"generate\"\n",
    "\n",
    "# --- 그래프 구성 ---\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"web_search_node\", web_search_node)\n",
    "\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\"transform_query\": \"transform_query\", \"generate\": \"generate\"}\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c6ec19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "{'retrieve': {'documents': [], 'question': 'Gemini 2.5 Pro는 무엇이 달라졌나요?', 'chat_history': []}}\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "{'grade_documents': {'documents': [], 'question': 'Gemini 2.5 Pro는 무엇이 달라졌나요?', 'web_search': 'No', 'chat_history': []}}\n",
      "---GENERATE---\n",
      "{'generate': {'documents': [], 'question': 'Gemini 2.5 Pro는 무엇이 달라졌나요?', 'generation': '제공된 문서의 내용으로는 답변할 수 없습니다.', 'chat_history': []}}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"Gemini 2.5 Pro는 무엇이 달라졌나요?\", \"chat_history\": []}\n",
    "for output in app.stream(inputs):\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a7d9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_community\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "382bada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Vector store already populated. Count=174\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# PDF Conversational RAG + CRAG(Conditional RAG) 통합 버전 (Gradio UI)\n",
    "# - PDF → LlamaParse(md) → Chroma(Parent/Child) → History-Aware Retrieve\n",
    "# - CRAG: grade_documents → (generate | transform_query → web_search → generate)\n",
    "# - 문서 외 지식 금지, 없으면 한국어로 \"제공된 문서...\" 출력\n",
    "# - 웹검색: Tavily(선택, 미설정 시 우회)\n",
    "# ================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import traceback\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Python typing\n",
    "from typing import Iterable, Optional, Tuple, List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# PDF Parser\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "# LangChain Core / OpenAI / Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# LangChain Core (Prompts, Messages, Output parsing)\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.stores import BaseStore  # ✅ BaseStore는 여기로 이동됨\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "# Pydantic (v2)\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# (Optional) 웹 검색 툴\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "\n",
    "# --- Add: Persistent JSON-backed DocStore for parents ---\n",
    "\n",
    "\n",
    "class JSONDocStore(BaseStore[str, Document]):\n",
    "    \"\"\"\n",
    "    간단한 파일 기반 영구 DocStore.\n",
    "    - key -> ./parent_store/{key}.json 에 Document 저장\n",
    "    - ParentDocumentRetriever 가 요구하는 mset/mget/mdelete/yield_keys 구현\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir: str = \"./parent_store\"):\n",
    "        self.root_dir = root_dir\n",
    "        os.makedirs(self.root_dir, exist_ok=True)\n",
    "\n",
    "    def _path(self, key: str) -> str:\n",
    "        return os.path.join(self.root_dir, f\"{key}.json\")\n",
    "\n",
    "    def mset(self, key_value_pairs: Iterable[Tuple[str, Document]]) -> None:\n",
    "        for key, doc in key_value_pairs:\n",
    "            with open(self._path(key), \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(\n",
    "                    {\"page_content\": doc.page_content, \"metadata\": doc.metadata},\n",
    "                    f,\n",
    "                    ensure_ascii=False,\n",
    "                )\n",
    "\n",
    "    def mget(self, keys: Iterable[str]) -> List[Optional[Document]]:\n",
    "        results: List[Optional[Document]] = []\n",
    "        for key in keys:\n",
    "            p = self._path(key)\n",
    "            if os.path.exists(p):\n",
    "                with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "                results.append(\n",
    "                    Document(\n",
    "                        page_content=data.get(\"page_content\", \"\"),\n",
    "                        metadata=data.get(\"metadata\", {}),\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                results.append(None)\n",
    "        return results\n",
    "\n",
    "    def mdelete(self, keys: Iterable[str]) -> None:\n",
    "        for key in keys:\n",
    "            p = self._path(key)\n",
    "            if os.path.exists(p):\n",
    "                os.remove(p)\n",
    "\n",
    "    def yield_keys(self, prefix: Optional[str] = None) -> Iterable[str]:\n",
    "        for fname in os.listdir(self.root_dir):\n",
    "            if not fname.endswith(\".json\"):\n",
    "                continue\n",
    "            key = fname[:-5]  # strip .json\n",
    "            if prefix is None or key.startswith(prefix):\n",
    "                yield key\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 환경변수 로드 & 설정\n",
    "# --------------------------\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LLAMA_KEY = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "TAVILY_KEY = os.getenv(\"TAVILY_API_KEY\")  # 없으면 웹검색 보강은 건너뜀\n",
    "\n",
    "# --------------------------\n",
    "# 경로 및 전역 설정\n",
    "# --------------------------\n",
    "PDF_PATH = \"data/gemini-2.5-tech_1-10.pdf\"\n",
    "PARSED_MD_PATH = \"loaddata/llamaparse_output_gemini_1-10.md\"\n",
    "CHROMA_DB_DIR = \"./chroma_db10\"\n",
    "\n",
    "# --------------------------\n",
    "# LLM & 임베딩\n",
    "# --------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# --------------------------\n",
    "# Text Splitters\n",
    "# --------------------------\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "\n",
    "# --------------------------\n",
    "# Vector Store (Chroma)\n",
    "# --------------------------\n",
    "vectorstore = Chroma(persist_directory=CHROMA_DB_DIR, embedding_function=embeddings)\n",
    "\n",
    "# --------------------------\n",
    "# ParentDocumentRetriever\n",
    "# --------------------------\n",
    "# 기존: store = InMemoryStore()\n",
    "store = JSONDocStore(\"./parent_store\")  # 파일 기반 parent 저장\n",
    "\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    "    search_kwargs={\"k\": 2},\n",
    ")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 데이터 로딩 & 벡터DB 적재\n",
    "# --------------------------\n",
    "def _vs_count_safe() -> int:\n",
    "    # 내부 속성 의존을 최소화하는 안전한 카운트 함수\n",
    "    try:\n",
    "        return vectorstore._collection.count()  # chroma 내부\n",
    "    except Exception:\n",
    "        try:\n",
    "            # 간단히 비슷문서 조회 시도 (비어있으면 예외 or 빈 결과)\n",
    "            _ = vectorstore.similarity_search(\"dummy\", k=1)\n",
    "            # Chroma는 비어있어도 호출이 성공할 수 있으므로 peek 써봄\n",
    "            return len(vectorstore._collection.peek()[\"ids\"])  # type: ignore\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "def load_and_populate_vectorstore():\n",
    "    os.makedirs(os.path.dirname(PARSED_MD_PATH), exist_ok=True)\n",
    "    os.makedirs(CHROMA_DB_DIR, exist_ok=True)\n",
    "\n",
    "    if _vs_count_safe() > 0:\n",
    "        print(f\"[INFO] Vector store already populated. Count={_vs_count_safe()}\")\n",
    "        return\n",
    "\n",
    "    # MD 파일 없으면 PDF → LlamaParse → md 저장\n",
    "    if not os.path.exists(PARSED_MD_PATH):\n",
    "        print(f\"[INFO] '{PARSED_MD_PATH}' not found. Parsing PDF with LlamaParse...\")\n",
    "        if not LLAMA_KEY:\n",
    "            raise RuntimeError(\"LLAMA_CLOUD_API_KEY가 없어 PDF 파싱을 수행할 수 없습니다.\")\n",
    "        try:\n",
    "            parser = LlamaParse(result_type=\"markdown\", api_key=LLAMA_KEY)\n",
    "            documents = parser.load_data(PDF_PATH)\n",
    "            md_text = \"\\n\".join([doc.text for doc in documents])\n",
    "            with open(PARSED_MD_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(md_text)\n",
    "            print(f\"[INFO] Parsed & saved to '{PARSED_MD_PATH}'\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"LlamaParse 오류: {e}\")\n",
    "\n",
    "    # md 로드 → Parent retriever에 추가\n",
    "    print(f\"[INFO] Loading markdown from '{PARSED_MD_PATH}'...\")\n",
    "    with open(PARSED_MD_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # 하나의 거대 문서로 추가 → Parent/Child splitter가 내부에서 잘게 쪼갬\n",
    "    documents = [Document(page_content=text, metadata={\"source\": PARSED_MD_PATH})]\n",
    "    retriever.add_documents(documents)\n",
    "    print(f\"[INFO] Vector store populated. Count={_vs_count_safe()}\")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# History-Aware Retriever\n",
    "# --------------------------\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood without the chat history. \"\n",
    "    \"Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)\n",
    "\n",
    "# --------------------------\n",
    "# 최종 답변(문서 기반만 허용) Chain\n",
    "# --------------------------\n",
    "ga_system_prompt = (\n",
    "    \"You are a helpful assistant. Your task is to answer the user's question based on the provided context. \"\n",
    "    \"The context may come from PDF documents or from web search results. \"\n",
    "    \"If useful information is present in the context (including web search), provide a concise answer. \"\n",
    "    \"If the answer cannot be found within the provided context, you MUST say '제공된 문서나 검색 결과의 내용으로는 답변할 수 없습니다.' \"\n",
    "    \"\\n\\nContext:\\n{context}\"\n",
    ")\n",
    "\n",
    "ga_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", ga_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, ga_prompt)\n",
    "\n",
    "# --------------------------\n",
    "# CRAG: 문서 관련성 평가(Structured Output)\n",
    "# --------------------------\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "    binary_score: str = Field(description=\"Documents are relevant to the question, 'yes' or 'no'\")\n",
    "\n",
    "grade_system_prompt = \"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
    "Return 'yes' or 'no'.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", grade_system_prompt),\n",
    "        (\"human\", \"Retrieved document:\\n\\n{document}\\n\\nUser question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "# --------------------------\n",
    "# CRAG: 질문 재작성 (웹검색 친화적)\n",
    "# --------------------------\n",
    "rewrite_system = (\n",
    "    \"You are a question re-writer that converts an input question to a better version optimized for web search. \"\n",
    "    \"Reason about the underlying semantic intent and produce a clearer query.\"\n",
    ")\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", rewrite_system),\n",
    "        (\"human\", \"Here is the initial question:\\n\\n{question}\\n\\nFormulate an improved question.\"),\n",
    "    ]\n",
    ")\n",
    "question_rewriter = rewrite_prompt | llm | StrOutputParser()\n",
    "\n",
    "# --------------------------\n",
    "# (선택) 웹검색 도구\n",
    "# --------------------------\n",
    "web_search_tool: Optional[TavilySearch] = None\n",
    "if TAVILY_KEY:\n",
    "    web_search_tool = TavilySearch(k=3)\n",
    "else:\n",
    "    print(\"[WARN] TAVILY_API_KEY 미설정: 웹검색 보강은 생략됩니다.\")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# LangGraph 상태 정의\n",
    "# --------------------------\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[Document]\n",
    "    chat_history: List  # HumanMessage/AIMessage 리스트\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# LangGraph 노드 함수\n",
    "# --------------------------\n",
    "def node_retrieve(state: GraphState) -> GraphState:\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "    chat_history = state.get(\"chat_history\", [])\n",
    "    docs = history_aware_retriever.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "    return {\"documents\": docs, \"question\": question, \"chat_history\": chat_history, \"web_search\": \"No\", \"generation\": \"\"}\n",
    "\n",
    "def node_grade_documents(state: GraphState) -> GraphState:\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    filtered_docs: List[Document] = []\n",
    "    for d in documents:\n",
    "        try:\n",
    "            score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "            if score.binary_score.strip().lower() == \"yes\":\n",
    "                print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "                filtered_docs.append(d)\n",
    "            else:\n",
    "                print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "        except Exception:\n",
    "            # 그레이더 실패 시 일단 보수적으로 유지\n",
    "            filtered_docs.append(d)\n",
    "\n",
    "    web_search_flag = \"Yes\" if len(filtered_docs) == 0 else \"No\"\n",
    "    return {\n",
    "        \"documents\": filtered_docs,\n",
    "        \"question\": question,\n",
    "        \"web_search\": web_search_flag,\n",
    "        \"chat_history\": state[\"chat_history\"],\n",
    "        \"generation\": state.get(\"generation\", \"\"),\n",
    "    }\n",
    "\n",
    "def node_decide_to_generate(state: GraphState) -> str:\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    return \"transform_query\" if state[\"web_search\"] == \"Yes\" else \"generate\"\n",
    "\n",
    "def node_transform_query(state: GraphState) -> GraphState:\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    better_question = question_rewriter.invoke({\"question\": state[\"question\"]})\n",
    "    return {\n",
    "        \"documents\": state[\"documents\"],\n",
    "        \"question\": better_question,\n",
    "        \"web_search\": state[\"web_search\"],\n",
    "        \"chat_history\": state[\"chat_history\"],\n",
    "        \"generation\": state.get(\"generation\", \"\"),\n",
    "    }\n",
    "\n",
    "def node_web_search(state: GraphState) -> GraphState:\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    documents = state[\"documents\"]\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    if web_search_tool is None:\n",
    "        # 웹검색 불가 시 안내 문서 추가\n",
    "        web_results_text = \"웹검색 API 키가 설정되지 않아 웹검색을 수행하지 못했습니다.\"\n",
    "    else:\n",
    "        try:\n",
    "            results = web_search_tool.invoke({\"query\": question})\n",
    "            lines = []\n",
    "            for r in results:\n",
    "                # r keys: content, url, score, title 등\n",
    "                title = r.get(\"title\") or \"\"\n",
    "                url = r.get(\"url\") or \"\"\n",
    "                content = r.get(\"content\") or \"\"\n",
    "                lines.append(f\"[{title}] {url}\\n{content}\\n\")\n",
    "            web_results_text = \"\\n---\\n\".join(lines) if lines else \"검색결과가 비어 있습니다.\"\n",
    "        except Exception as e:\n",
    "            web_results_text = f\"웹검색 중 오류: {e}\"\n",
    "\n",
    "    documents = documents + [Document(page_content=web_results_text, metadata={\"source\": \"tavily\"})]\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "        \"question\": question,\n",
    "        \"web_search\": \"No\",\n",
    "        \"chat_history\": state[\"chat_history\"],\n",
    "        \"generation\": state.get(\"generation\", \"\"),\n",
    "    }\n",
    "\n",
    "def node_generate(state: GraphState) -> GraphState:\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    chat_history = state[\"chat_history\"]\n",
    "\n",
    "    # 답변 생성\n",
    "    answer = question_answer_chain.invoke({\n",
    "        \"input\": question,\n",
    "        \"chat_history\": chat_history,\n",
    "        \"context\": documents\n",
    "    })\n",
    "\n",
    "    # 출처 구분\n",
    "    if any(d.metadata.get(\"source\") == \"tavily\" for d in documents):\n",
    "        source_tag = \"\\n\\n[출처: 웹검색 결과]\"\n",
    "    else:\n",
    "        source_tag = \"\\n\\n[출처: PDF 문서]\"\n",
    "\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "        \"question\": question,\n",
    "        \"web_search\": \"No\",\n",
    "        \"chat_history\": chat_history,\n",
    "        \"generation\": (answer if isinstance(answer, str) else str(answer)) + source_tag,\n",
    "    }\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 그래프 구성 & 컴파일\n",
    "# --------------------------\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"retrieve\", node_retrieve)\n",
    "workflow.add_node(\"grade_documents\", node_grade_documents)\n",
    "workflow.add_node(\"generate\", node_generate)\n",
    "workflow.add_node(\"transform_query\", node_transform_query)\n",
    "workflow.add_node(\"web_search_node\", node_web_search)\n",
    "\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    node_decide_to_generate,\n",
    "    {\"transform_query\": \"transform_query\", \"generate\": \"generate\"},\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 유틸: Gradio용 히스토리 변환\n",
    "# --------------------------\n",
    "def to_lc_messages(history: List[dict]) -> List:\n",
    "    msgs = []\n",
    "    for m in history:\n",
    "        if m[\"role\"] == \"user\":\n",
    "            msgs.append(HumanMessage(content=m[\"content\"]))\n",
    "        elif m[\"role\"] == \"assistant\":\n",
    "            msgs.append(AIMessage(content=m[\"content\"]))\n",
    "    return msgs\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Gradio 핸들러\n",
    "# --------------------------\n",
    "def run_crag(query: str, history: List[dict]):\n",
    "    # 1) Chat history 변환\n",
    "    chat_history_for_chain = to_lc_messages(history or [])\n",
    "\n",
    "    # 2) 그래프 실행\n",
    "    try:\n",
    "        final_state = None\n",
    "        inputs = {\"question\": query, \"chat_history\": chat_history_for_chain, \"documents\": [], \"web_search\": \"No\", \"generation\": \"\"}\n",
    "        for step in app.stream(inputs):\n",
    "            # 디버깅 로그(선택)\n",
    "            for node_name, node_state in step.items():\n",
    "                print(f\"[TRACE] Node '{node_name}' passed.\")\n",
    "            final_state = node_state  # 마지막 state\n",
    "\n",
    "        # 3) 최종 응답/문서 정리\n",
    "        answer = final_state.get(\"generation\", \"제공된 문서의 내용으로는 답변할 수 없습니다.\")\n",
    "        docs: List[Document] = final_state.get(\"documents\", [])\n",
    "        context_md = \"## 참조 문서\\n\\n\"\n",
    "        if docs:\n",
    "            for i, d in enumerate(docs, 1):\n",
    "                src = d.metadata.get(\"source\", \"N/A\")\n",
    "                snippet = d.page_content[:800] + (\"...\" if len(d.page_content) > 800 else \"\")\n",
    "                context_md += f\"### 문서 {i} (source: {src})\\n```\\n{snippet}\\n```\\n\\n\"\n",
    "        else:\n",
    "            context_md += \"참조된 문서가 없습니다.\"\n",
    "\n",
    "        # 4) 히스토리에 추가\n",
    "        if history is None:\n",
    "            history = []\n",
    "        history.append({\"role\": \"user\", \"content\": query})\n",
    "        history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "        return \"\", history, context_md\n",
    "\n",
    "    except Exception as e:\n",
    "        err = f\"오류 발생: {e}\\n{traceback.format_exc()}\"\n",
    "        if history is None:\n",
    "            history = []\n",
    "        history.append({\"role\": \"user\", \"content\": query})\n",
    "        history.append({\"role\": \"assistant\", \"content\": \"오류가 발생했습니다. 콘솔 로그를 확인하세요.\"})\n",
    "        return \"\", history, f\"### 오류\\n```\\n{err}\\n```\"\n",
    "\n",
    "\n",
    "def force_reload_vectorstore():\n",
    "    try:\n",
    "        print(\"[INFO] Resetting Chroma client...\")\n",
    "        vectorstore._client.reset()  # 전체 컬렉션 초기화\n",
    "        load_and_populate_vectorstore()\n",
    "        return \"✅ Vector store reloaded successfully!\"\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error during vector store reload: {e}\"\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 초기 적재\n",
    "# --------------------------\n",
    "load_and_populate_vectorstore()\n",
    "\n",
    "# --------------------------\n",
    "# Gradio UI\n",
    "# --------------------------\n",
    "example_questions = [\n",
    "    \"Gemini 2.5 Pro는 Gemini 1.5 Pro와 비교했을 때 어떤 점에서 향상되었나요?\",\n",
    "    \"Gemini 2.5 Pro와 Flash는 어떤 종류의 데이터를 처리할 수 있나요?\",\n",
    "    \"Gemini 2.5 시리즈의 작은 모델들은 어떤 방식으로 성능을 개선했나요?\",\n",
    "]\n",
    "\n",
    "with gr.Blocks(theme=\"soft\", title=\"PDF RAG + CRAG Chatbot\") as demo:\n",
    "    gr.Markdown(\"# PDF RAG + CRAG Chatbot (LlamaParse / ParentRetriever / History-Aware / Web Search)\")\n",
    "    gr.Markdown(\"PDF 문서 내용에 대해 질문하세요. 문서에서 못 찾으면 질문 재작성 + (선택)웹검색으로 보강합니다.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            chatbot = gr.Chatbot(height=420, label=\"Chat\", type=\"messages\", value=[])\n",
    "            msg = gr.Textbox(label=\"질문을 입력하세요... (Shift+Enter 줄바꿈)\")\n",
    "\n",
    "            gr.Examples(examples=example_questions, inputs=msg, label=\"예시 질문\")\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            context_display = gr.Markdown(label=\"LLM 참조 문서 전문/요약\")\n",
    "            with gr.Accordion(\"⚙️ Advanced Options\", open=False):\n",
    "                reload_button = gr.Button(\"🔄 Force Reload Vector Store\")\n",
    "                reload_status = gr.Markdown()\n",
    "\n",
    "    clear = gr.ClearButton([msg, chatbot, context_display])\n",
    "    msg.submit(run_crag, [msg, chatbot], [msg, chatbot, context_display])\n",
    "    reload_button.click(force_reload_vectorstore, outputs=reload_status)\n",
    "\n",
    "# demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2bd54b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
